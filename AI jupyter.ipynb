{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec20cf-11fb-4b8b-bdfc-dce31151be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge scikit-surprise -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d75e78-bb7d-486c-9beb-e5559dc720a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from collections import Counter, defaultdict\n",
    "from ast import literal_eval  \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "#from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from ast import literal_eval \n",
    "from surprise import accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65ff6a-eeb7-4694-9151-c29bc5bf30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec5f5f-27c5-4510-8269-c4e1b051dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "credit = pd.read_csv(\"credits.xls\")\n",
    "title = pd.read_csv(\"titles.xls\")\n",
    "user= pd.read_csv(\"user_interactions.xls\")\n",
    "\n",
    "print(\"credit data\")\n",
    "print(credit.head().to_string())\n",
    "print(credit.tail().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d377242b-80e6-409c-8a0c-bdffa2aba32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"title data\")\n",
    "print(title.head().to_string())\n",
    "print(title.tail().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd4334-1929-4ebf-bd5c-063e89626a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User data\")\n",
    "print(user.head().to_string())\n",
    "print(user.tail().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7296d1fd-4992-43db-b02d-6e1d651098c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate credit details before merging\n",
    "credit_agg = credit.groupby(\"id\").agg({\n",
    "    \"person_id\": list,  \n",
    "    \"name\": list,      \n",
    "    \"character\": list,  \n",
    "    \"role\": list       \n",
    "}).reset_index()\n",
    "\n",
    "#Merge titles with aggregated credits\n",
    "combine = title.merge(credit_agg, on=\"id\", how=\"left\")\n",
    "\n",
    "#Merge user interactions with the combined titles+credits dataset\n",
    "final_data = user.merge(combine, left_on=\"id\", right_on=\"id\", how=\"left\")\n",
    "\n",
    "# Display final merged dataset\n",
    "print(\"\\nFinal Merged Dataset:\")\n",
    "print(final_data.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389bbe0-fb82-49b1-8e7d-f36c10e273bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the shape of the merged dataset\n",
    "print(\"Number of Rows and Columns in Merged Data:\", final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda2552a-5926-42b8-9943-3ea38ad40d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show column details\n",
    "print(\"\\nColumns in final DataFrame:\")\n",
    "print(final_data .columns)\n",
    "\n",
    "print(\"\\nDataset Information:\")\n",
    "print(final_data .info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ff583-8e69-4423-a9e6-0ccfea58800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing value checking\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(final_data .isnull().sum())\n",
    "\n",
    " # Missing Values Percentage\n",
    "print(\"\\nMissing Values Percentage in Each Column:\")\n",
    "round(final_data .isnull().sum()/len(final_data )*100, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad46d30-b629-41e3-b2dc-4679d99dd284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary Statistics:\")\n",
    "print(final_data .describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6489fe-cd78-4588-a1ee-a4d82f0f044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "sns.histplot(final_data['imdb_score'], bins=30, kde=True, color='blue', label='IMDb Score')\n",
    "sns.histplot(final_data['tmdb_score'], bins=30, kde=True, color='red', label='TMDb Score')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of IMDb & TMDb Scores\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec6cf6-c305-476f-8783-e41af8fd0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show most popular genres\n",
    "# Convert genres from string format to a list\n",
    "all_genres = [genre for sublist in final_data['genres'].dropna().apply(lambda x: x.split(',')) for genre in sublist]\n",
    "\n",
    "# Count occurrences\n",
    "genre_counts = Counter(all_genres)\n",
    "\n",
    "# Convert to DataFrame for visualization\n",
    "genre_combine = pd.DataFrame(genre_counts.items(), columns=['Genre', 'Count']).sort_values(by='Count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=genre_combine['Genre'], y=genre_combine['Count'], palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels for better readability\n",
    "plt.xlabel(\"Genre\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Most Common Movie/TV Show Genres\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865574d-04fb-47e6-a933-a428cc53bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove redundant features\n",
    "# Select only numerical columns from final_data\n",
    "numeric_cols = final_data.select_dtypes(include=['number'])\n",
    "\n",
    "# Compute correlation on numerical columns only\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numeric_cols.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "plt.title(\"ðŸ”— Feature Correlation Heatmap\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636d42d-cae0-41ce-8a42-74de37a5b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values \n",
    "final_data['title'] = final_data['title'].fillna('Unknown Title')\n",
    "final_data['description'] = final_data['description'].fillna('No description available')\n",
    "final_data['age_certification'] = final_data['age_certification'].fillna('Not Rated')\n",
    "final_data['seasons'] = final_data['seasons'].fillna(0)\n",
    "final_data['imdb_id'] = final_data['imdb_id'].fillna('Unknown')\n",
    "\n",
    "# Fill numerical columns with appropriate statistics\n",
    "final_data['imdb_score'] = final_data['imdb_score'].fillna(final_data['imdb_score'].mean())\n",
    "final_data['tmdb_score'] = final_data['tmdb_score'].fillna(final_data['tmdb_score'].mean())\n",
    "final_data['imdb_votes'] = final_data['imdb_votes'].fillna(final_data['imdb_votes'].median())\n",
    "final_data['tmdb_popularity'] = final_data['tmdb_popularity'].fillna(final_data['tmdb_popularity'].median())\n",
    "\n",
    "# Fill missing credits data\n",
    "final_data[['person_id', 'name', 'character', 'role']] = final_data[['person_id', 'name', 'character', 'role']].fillna('Unknown')\n",
    "\n",
    "# Fill missing user data\n",
    "final_data['user_id'] = final_data['user_id'].fillna('Unknown User')\n",
    "final_data['rating'] = final_data['rating'].fillna(final_data['rating'].median())  # Assuming ratings are numeric\n",
    "\n",
    "# Print remaining missing values\n",
    "print(final_data.isna().sum())\n",
    "print(final_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ca27bd-e24e-4d40-852a-57e00e154c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting numerical features\n",
    "num_features = ['runtime', 'imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score', 'rating']\n",
    "\n",
    "# outlier detection\n",
    "plt.figure(figsize=(12, 6))\n",
    "final_data[num_features].boxplot()\n",
    "plt.title(\"Boxplot of Numerical Features (Outlier Detection)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfed73b-52af-40d8-8d9a-8f7f3cf752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(final_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Outlier detection using IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "\n",
    "# Apply outlier removal only to training set\n",
    "num_features = ['imdb_score', 'imdb_votes', 'tmdb_score', 'tmdb_popularity', 'rating']\n",
    "\n",
    "for col in num_features:\n",
    "    outliers = detect_outliers_iqr(train, col)\n",
    "    train = train.drop(outliers.index)\n",
    "\n",
    "print(\"Training dataset shape after outlier removal:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd6551-2c87-4648-9827-1ef3a6043625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# List of numerical features to normalize\n",
    "num_features = ['imdb_score', 'imdb_votes', 'tmdb_score', 'tmdb_popularity']\n",
    "\n",
    "# Fit on training data and transform both train and test sets\n",
    "train.loc[:, num_features] = scaler.fit_transform(train[num_features])\n",
    "test.loc[:, num_features] = scaler.transform(test[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a0b5c-9209-46e6-99bc-7b065453b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#  text preprocessing\n",
    "def preprocess_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"unknown\"  # Handle missing text\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove special characters and numbers to keep only letters and spaces\n",
    "\n",
    "    # Tokenization \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    # If all tokens are stop words or the text becomes empty, return \"unknown\" to avoid empty text\n",
    "    if not tokens:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "# Apply preprocessing to the training and test sets' textual columns\n",
    "train['description'] = train['description'].apply(preprocess_text)\n",
    "test['description'] = test['description'].apply(preprocess_text)\n",
    "\n",
    "train['title'] = train['title'].apply(preprocess_text)\n",
    "test['title'] = test['title'].apply(preprocess_text)\n",
    "\n",
    "train['character'] = train['character'].apply(lambda x: preprocess_text(str(x)))\n",
    "test['character'] = test['character'].apply(lambda x: preprocess_text(str(x)))\n",
    "\n",
    "print(train[['title', 'description', 'character']].head())\n",
    "print(test[['title', 'description', 'character']].head())\n",
    "\n",
    "# Create combined text-based features for TF-IDF processing\n",
    "train['text_features'] = (\n",
    "    train['genres'].fillna('') + \" \" +\n",
    "    train['production_countries'].fillna('') + \" \" +\n",
    "    train['description'].fillna('')\n",
    ")\n",
    "\n",
    "test['text_features'] = (\n",
    "    test['genres'].fillna('') + \" \" +\n",
    "    test['production_countries'].fillna('') + \" \" +\n",
    "    test['description'].fillna('')\n",
    ")\n",
    "\n",
    "# Apply TF-IDF Vectorization \n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000, min_df=1) #min_df can be increased for more rigorous text filtering\n",
    "\n",
    "# Remove rows with empty text features\n",
    "train = train[train['text_features'].str.strip() != '']\n",
    "test = test[test['text_features'].str.strip() != '']\n",
    "\n",
    "# Apply TF-IDF \n",
    "tfidf_matrix_train = tfidf.fit_transform(train['text_features'])\n",
    "tfidf_matrix_test = tfidf.transform(test['text_features'])\n",
    "print(f\"TF-IDF Matrix Train Shape: {tfidf_matrix_train.shape}\")\n",
    "print(f\"TF-IDF Matrix Test Shape: {tfidf_matrix_test.shape}\")\n",
    "\n",
    "# Select and scale numeric features\n",
    "numeric_features = train[['release_year']].fillna(train[['release_year']].mean())  # Fill missing values with mean\n",
    "scaler = MinMaxScaler()\n",
    "numeric_scaled_train = scaler.fit_transform(numeric_features)\n",
    "numeric_scaled_test = scaler.transform(test[['release_year']])\n",
    "\n",
    "# Convert numeric features to sparse matrix format\n",
    "numeric_scaled_train = csr_matrix(numeric_scaled_train)\n",
    "numeric_scaled_test = csr_matrix(numeric_scaled_test)\n",
    "\n",
    "# Combine text and numeric features into sparse matrices\n",
    "combined_features_train = hstack([tfidf_matrix_train, numeric_scaled_train]).tocsr()\n",
    "combined_features_test = hstack([tfidf_matrix_test, numeric_scaled_test]).tocsr()\n",
    "\n",
    "# Handle nullvalues by replacing with 0 for sparse matrices\n",
    "combined_features_train = combined_features_train.copy()\n",
    "combined_features_train.data[np.isnan(combined_features_train.data)] = 0\n",
    "combined_features_test = combined_features_test.copy()\n",
    "combined_features_test.data[np.isnan(combined_features_test.data)] = 0\n",
    "\n",
    "# Compute cosine similarity between training and  test samples\n",
    "cosine_sim_train = cosine_similarity(combined_features_train, combined_features_train)\n",
    "cosine_sim_test = cosine_similarity(combined_features_test, combined_features_test)\n",
    "\n",
    "# Convert similarity matrix \n",
    "similarity_df_train = pd.DataFrame(cosine_sim_train, index=train.index, columns=train.index)\n",
    "similarity_df_test = pd.DataFrame(cosine_sim_test, index=test.index, columns=test.index)\n",
    "\n",
    "print(similarity_df_train.head())\n",
    "print(similarity_df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ce173-3435-40ef-867e-0d899148fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#content-based\n",
    "\n",
    "def get_recommendations(user_type=None, user_release_year=None, user_genres=None, user_countries=None, n=10):\n",
    "    filtered_data = test.copy()\n",
    "\n",
    "    if user_type:\n",
    "        filtered_data = filtered_data[filtered_data['type'].str.contains(user_type, case=False, na=False)]\n",
    "    if user_release_year:\n",
    "        filtered_data = filtered_data[filtered_data['release_year'] == user_release_year]\n",
    "    if user_genres:\n",
    "        filtered_data = filtered_data[filtered_data['genres'].apply(lambda x: user_genres.lower() in [g.lower() for g in literal_eval(x)] if isinstance(x, str) else False)]\n",
    "    if user_countries:\n",
    "        filtered_data = filtered_data[filtered_data['production_countries'].str.contains(user_countries, case=False, na=False)]\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        return \"No matching movies found!\"\n",
    "\n",
    "    filtered_data = filtered_data.drop_duplicates(subset='title')\n",
    "    \n",
    "    similar_movies = pd.Series(dtype='float64')\n",
    "\n",
    "    if 'similarity_df_test' in globals():  # Ensure similarity matrix exists\n",
    "        for idx in filtered_data.index:\n",
    "            if idx in similarity_df_test.index:\n",
    "                similar_movies = similar_movies.add(similarity_df_test.loc[idx], fill_value=0)\n",
    "\n",
    "    if similar_movies.empty:\n",
    "        return \"No similar movies found in the dataset!\"\n",
    "    \n",
    "    similar_movies = similar_movies.sort_values(ascending=False)\n",
    "    recommended_movies = test.loc[similar_movies.index, ['title', 'genres', 'rating']].drop_duplicates()\n",
    "\n",
    "    if len(recommended_movies) < n:\n",
    "        additional_recommendations = filtered_data[['title', 'genres', 'rating']].sort_values(by='rating', ascending=False).head(n - len(recommended_movies))\n",
    "        recommended_movies = pd.concat([recommended_movies, additional_recommendations])\n",
    "    \n",
    "    # Sort final recommendations by rating in descending order\n",
    "    recommended_movies = recommended_movies.sort_values(by='rating', ascending=False).head(n)\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "# User Input\n",
    "user_type = input(\"Enter movie type (Movie/Show) or press Enter to skip: \").strip() or None\n",
    "user_release_year = input(\"Enter release year or press Enter to skip: \").strip()\n",
    "user_release_year = int(user_release_year) if user_release_year else None\n",
    "user_genres = input(\"Enter genres or press Enter to skip: \").strip() or None\n",
    "user_countries = input(\"Enter production countries or press Enter to skip: \").strip() or None\n",
    "\n",
    "recommended_movies = get_recommendations(user_type, user_release_year, user_genres, user_countries, n=10)\n",
    "\n",
    "print(\"\\nTop 10 recommended Movies for you:\")\n",
    "if isinstance(recommended_movies, str):\n",
    "    print(recommended_movies)\n",
    "else:\n",
    "    for _, row in recommended_movies.iterrows():\n",
    "        print(f\"Movie Title: {row['title']}, Genres: {row['genres']}, Rating: {row.get('rating', 'N/A')}\")\n",
    "\n",
    "def evaluate_recommendations(y_true, y_pred):\n",
    "    threshold = 3\n",
    "    y_true_bin = [1 if rating >= threshold else 0 for rating in y_true]\n",
    "    y_pred_bin = [1 if rating >= threshold else 0 for rating in y_pred]\n",
    "\n",
    "    precision = precision_score(y_true_bin, y_pred_bin, zero_division=1)\n",
    "    recall = recall_score(y_true_bin, y_pred_bin, zero_division=1)\n",
    "    f1 = f1_score(y_true_bin, y_pred_bin, zero_division=1)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    return {\"RMSE\": rmse, \"Precision\": precision, \"F1-score\": f1, \"Recall\": recall}\n",
    "\n",
    "if isinstance(recommended_movies, str):\n",
    "    print(\"No recommendations to evaluate.\")\n",
    "else:\n",
    "    y_true = test['rating'].tolist()\n",
    "    y_pred = recommended_movies['rating'].fillna(test['rating'].mean()).tolist()  # Use mean rating for missing values\n",
    "    \n",
    "    # Ensure the lengths match\n",
    "    y_pred = y_pred[:len(y_true)] + [test['rating'].mean()] * (len(y_true) - len(y_pred))\n",
    "    \n",
    "    eval_metrics = evaluate_recommendations(y_true, y_pred)\n",
    "    \n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    for metric, value in sorted(eval_metrics.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0b305-01cc-4ad5-bc2c-9074f591cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collaborative-filtering\n",
    "!pip install -U setuptools wheel\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbc166-3f3c-4091-82f6-f2d2e07e47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "from collections import defaultdict\n",
    "\n",
    "# loaded final_data \n",
    "if 'final_data' not in globals():\n",
    "    raise ValueError(\"Error: 'final_data' dataset is not defined.\")\n",
    "\n",
    "# Create user-item matrix\n",
    "user_item_matrix = final_data.pivot_table(index='user_id', columns='id', values='rating')\n",
    "\n",
    "# Fill missing values with median ratings\n",
    "user_item_matrix_filled = user_item_matrix.apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "\n",
    "# Convert to long format\n",
    "long_format = final_data[['user_id', 'id', 'rating']].dropna(subset=['rating'])\n",
    "\n",
    "# Prepare dataset for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "dataset = Dataset.load_from_df(long_format[['user_id', 'id', 'rating']], reader)\n",
    "\n",
    "# Split data (80-20)\n",
    "trainset, testset = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100, 150],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.1, 0.2]\n",
    "}\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=5)\n",
    "grid_search.fit(dataset)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params['rmse'])\n",
    "print(\"Best RMSE Score:\", grid_search.best_score['rmse'])\n",
    "\n",
    "# Train best model\n",
    "best_svd = grid_search.best_estimator['rmse']\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "# Evaluate model\n",
    "predictions = best_svd.test(testset)\n",
    "rmse = accuracy.rmse(predictions, verbose=False)\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "# evaluation matric Calculation\n",
    "def precision_recall_at_k(predictions, k=5, threshold=3.0):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions, recalls = [], []\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(reverse=True, key=lambda x: x[0])\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum((true_r >= threshold) and (est >= threshold) for (est, true_r) in user_ratings[:k])\n",
    "        \n",
    "        precision = n_rel_and_rec_k / n_rec_k if n_rec_k else 0\n",
    "        recall = n_rel_and_rec_k / n_rel if n_rel else 0\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    precision_avg = np.mean(precisions)\n",
    "    recall_avg = np.mean(recalls)\n",
    "    f1_score_avg = (2 * precision_avg * recall_avg / (precision_avg + recall_avg)) if (precision_avg + recall_avg) else 0\n",
    "    \n",
    "    return precision_avg, recall_avg, f1_score_avg\n",
    "\n",
    "precision, recall, f1_score = precision_recall_at_k(predictions, k=5, threshold=3.0)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1_score:.4f}\")\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_for_user(user_id, n_recommendations=5):\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return [(\"User not found in dataset\", None, None)]\n",
    "\n",
    "    all_items = final_data['id'].unique()\n",
    "    rated_items = user_item_matrix.loc[user_id].dropna().index\n",
    "    items_to_predict = [item for item in all_items if item not in rated_items]\n",
    "    \n",
    "    if not items_to_predict:\n",
    "        return [(\"No new recommendations available\", None, None)]\n",
    "    \n",
    "    predictions = [best_svd.predict(user_id, item_id) for item_id in items_to_predict]\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    top_n_recommendations = predictions[:n_recommendations]\n",
    "    \n",
    "    # Move the recommended_movies inside the function properly\n",
    "    recommended_items = [\n",
    "        (\n",
    "            pred.iid,  \n",
    "            final_data.loc[final_data['id'] == pred.iid, 'title'].values[0] if not final_data.loc[final_data['id'] == pred.iid, 'title'].empty else \"Unknown Title\",\n",
    "            round(pred.est, 1)\n",
    "        ) for pred in top_n_recommendations\n",
    "    ]\n",
    "    \n",
    "    return recommended_items  \n",
    "\n",
    "\n",
    "# Get user input\n",
    "try:\n",
    "    user_id_input = int(input(\"Enter your user ID: \").strip())\n",
    "    top_recommendations = recommend_for_user(user_id_input, n_recommendations=10)\n",
    "    \n",
    "    print(\"\\nTop 10 recommended items:\")\n",
    "    \n",
    "    for item_id, movie_title, predicted_rating in top_recommendations:\n",
    "        print(f\"Item ID: {item_id}, Movie Title: {movie_title}, Predicted Rating: {predicted_rating}\")\n",
    "\n",
    "except ValueError:\n",
    "    print(\"Invalid input! Please enter a valid numeric user ID.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482de4c2-cd03-4c2d-a85e-764d202cf9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight hybrid system\n",
    "\n",
    "# loaded final_data dataset\n",
    "if 'final_data' not in globals():\n",
    "    raise ValueError(\"Error: 'final_data' dataset is not defined.\")\n",
    "\n",
    "# Prepare data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "dataset = Dataset.load_from_df(final_data[['user_id', 'id', 'rating']], reader)\n",
    "\n",
    "# Train-Test Split (80-20)\n",
    "trainset, testset = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "# Train the best collaborative filtering model (SVD)\n",
    "svd = SVD(n_factors=100, lr_all=0.005, reg_all=0.1)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Content-Based Filtering: Precompute Similarities\n",
    "content_features = final_data[['id', 'title', 'genres', 'production_countries', 'release_year']]\n",
    "content_features['genres'] = content_features['genres'].apply(lambda x: literal_eval(x) if isinstance(x, str) else [])\n",
    "content_features['production_countries'] = content_features['production_countries'].apply(lambda x: literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "def compute_content_similarity(movie_id, user_genres, user_countries):\n",
    "    \"\"\"Compute content similarity score based on genres and production countries.\"\"\"\n",
    "    if movie_id not in content_features['id'].values:\n",
    "        return 0  # If the movie is not found, return 0 similarity\n",
    "    \n",
    "    movie_row = content_features[content_features['id'] == movie_id].iloc[0]\n",
    "    \n",
    "    genre_similarity = len(set(movie_row['genres']) & set(user_genres)) / len(set(user_genres)) if user_genres else 0\n",
    "    country_similarity = len(set(movie_row['production_countries']) & set(user_countries)) / len(set(user_countries)) if user_countries else 0\n",
    "    \n",
    "    return 0.7 * genre_similarity + 0.3 * country_similarity  # Weighted similarity\n",
    "\n",
    "def hybrid_recommend_for_user(user_id, n_recommendations=10, weight_cf=0.6, weight_cbf=0.4, genre_filter=None, year_filter=None):\n",
    "    # Check if the user exists in the dataset\n",
    "    if user_id not in final_data['user_id'].values:\n",
    "        print(\" User not found in dataset. Recommending top movies instead.\")\n",
    "        all_items = final_data['id'].unique()  # Use all movies\n",
    "    else:\n",
    "        user_movies = final_data[final_data['user_id'] == user_id]\n",
    "\n",
    "        # Extract user preferences (genres, countries)\n",
    "        user_genres = list(set([genre for genres in user_movies['genres'].apply(literal_eval) for genre in genres if genres]))\n",
    "        user_countries = list(set([country for countries in user_movies['production_countries'].apply(literal_eval) for country in countries if countries]))\n",
    "\n",
    "        all_items = final_data['id'].unique()\n",
    "\n",
    "    # Apply genre filter\n",
    "    if genre_filter:\n",
    "        genre_filter = genre_filter.lower()\n",
    "        filtered_items = [\n",
    "            item for item in all_items\n",
    "            if any(genre_filter in g.lower() for g in literal_eval(final_data.loc[final_data['id'] == item, 'genres'].values[0]))\n",
    "        ]\n",
    "        if not filtered_items:\n",
    "            print(\"No movies match the selected genre. Displaying top recommendations instead.\")\n",
    "        else:\n",
    "            all_items = filtered_items\n",
    "\n",
    "    # Apply year filter\n",
    "    if year_filter:\n",
    "        all_items = [\n",
    "            item for item in all_items\n",
    "            if final_data.loc[final_data['id'] == item, 'release_year'].values[0] == year_filter\n",
    "        ]\n",
    "        if not all_items:\n",
    "            print(\" No movies match the selected year. Displaying top recommendations instead.\")\n",
    "\n",
    "    # Ensure have movies to recommend\n",
    "    if not all_items:\n",
    "        return [(\"No recommendations available\", None)]\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    for item_id in all_items:\n",
    "        cf_score = svd.predict(user_id, item_id).est  # CF score\n",
    "        cbf_score = compute_content_similarity(item_id, user_genres, user_countries)  # CBF score\n",
    "        \n",
    "        final_score = (weight_cf * cf_score) + (weight_cbf * cbf_score)  # Hybrid score\n",
    "        predictions.append((item_id, final_score))\n",
    "\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)  # Sort by highest score\n",
    "    \n",
    "    top_n_recommendations = predictions[:n_recommendations]\n",
    "\n",
    "    recommended_items = [\n",
    "        (\n",
    "            pred[0],  # Movie ID\n",
    "            final_data.loc[final_data['id'] == pred[0], 'title'].values[0] if not final_data.loc[final_data['id'] == pred[0], 'title'].empty else \"Unknown Title\"\n",
    "        ) for pred in top_n_recommendations\n",
    "    ]\n",
    "    \n",
    "    return recommended_items\n",
    "\n",
    "\n",
    "#user input\n",
    "try:\n",
    "    user_id_input = int(input(\"Enter your user ID: \").strip())\n",
    "\n",
    "    genre_input = input(\"Enter a movie genre to filter (or press Enter to skip): \").strip().lower()\n",
    "    genre_filter = genre_input if genre_input else None\n",
    "\n",
    "    year_input = input(\"Enter a release year to filter (or press Enter to skip): \").strip()\n",
    "    year_filter = int(year_input) if year_input.isdigit() else None\n",
    "\n",
    "    top_recommendations = hybrid_recommend_for_user(user_id_input, n_recommendations=10, genre_filter=genre_filter, year_filter=year_filter)\n",
    "    \n",
    "    print(\"\\nTop 10 recommended movie:\")\n",
    "    \n",
    "    for item_id, movie_title in top_recommendations:\n",
    "        predicted_rating = svd.predict(user_id_input, item_id).est  # Get predicted rating\n",
    "        print(f\" Movie Title: {movie_title}(Predicted Rating: {predicted_rating:.2f})\")\n",
    "\n",
    "except ValueError:\n",
    "    print(\"Invalid input! Please enter a valid numeric user ID.\")\n",
    "\n",
    "# Evaluation\n",
    "test_predictions = svd.test(testset)\n",
    "\n",
    "# Define threshold for relevant recommendations\n",
    "threshold = 3.5 \n",
    "k = 10  # Top-K recommendations\n",
    "\n",
    "# Group predictions by user\n",
    "user_est_true = defaultdict(list)\n",
    "for uid, _, true_r, est, _ in test_predictions:\n",
    "    user_est_true[uid].append((est, true_r))\n",
    "\n",
    "# Compute RMSE and MAE once\n",
    "rmse = accuracy.rmse(test_predictions)\n",
    "mae = accuracy.mae(test_predictions)\n",
    "\n",
    "# Compute Precision and Recall\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "for uid, ratings in user_est_true.items():\n",
    "    ratings.sort(key=lambda x: x[0], reverse=True)  # Sort by predicted rating (desc)\n",
    "    top_k = ratings[:k]  # Get Top-K items\n",
    "    \n",
    "    relevant_items = sum((true_r >= threshold) for (_, true_r) in ratings)  # Actual good items\n",
    "    recommended_relevant = sum((true_r >= threshold) for (_, true_r) in top_k)  # Recommended good items\n",
    "\n",
    "    precision = recommended_relevant / k if k > 0 else 0\n",
    "    recall = recommended_relevant / relevant_items if relevant_items > 0 else 0\n",
    "\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "# Average Precision and Recall\n",
    "precision = sum(precision_list) / len(precision_list) if precision_list else 0\n",
    "recall = sum(recall_list) / len(recall_list) if recall_list else 0\n",
    "f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "#Ensure RMSE & MAE are displayed only once\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1_score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc10d26-e2e6-4bd2-90c8-729781e5cd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
